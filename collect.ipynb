{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f5b0b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to scrape ALL reviews...\n",
      "Attempting to scrape reviews from product page...\n",
      "Timeout waiting for #customerReviews, retrying... (attempt 1)\n",
      "Timeout waiting for #customerReviews, retrying... (attempt 2)\n",
      "Final timeout waiting for #customerReviews\n",
      "Attempting to navigate to reviews page...\n",
      "Successfully clicked 'See all reviews' link\n",
      "Scraping reviews page 1...\n",
      "Found 10 reviews on page 1\n",
      "Successfully extracted 10 reviews from page 1\n",
      "Scraping reviews page 2...\n",
      "Found 10 reviews on page 2\n",
      "Successfully extracted 10 reviews from page 2\n",
      "Scraping reviews page 3...\n",
      "Found 10 reviews on page 3\n",
      "Successfully extracted 10 reviews from page 3\n",
      "Scraping reviews page 4...\n",
      "Found 10 reviews on page 4\n",
      "Successfully extracted 10 reviews from page 4\n",
      "Scraping reviews page 5...\n",
      "Found 10 reviews on page 5\n",
      "Successfully extracted 10 reviews from page 5\n",
      "Scraping reviews page 6...\n",
      "Found 10 reviews on page 6\n",
      "Successfully extracted 10 reviews from page 6\n",
      "Scraping reviews page 7...\n",
      "Found 10 reviews on page 7\n",
      "Successfully extracted 10 reviews from page 7\n",
      "Scraping reviews page 8...\n",
      "Found 10 reviews on page 8\n",
      "Successfully extracted 10 reviews from page 8\n",
      "Scraping reviews page 9...\n",
      "Found 10 reviews on page 9\n",
      "Successfully extracted 10 reviews from page 9\n",
      "Scraping reviews page 10...\n",
      "Found 10 reviews on page 10\n",
      "Successfully extracted 10 reviews from page 10\n",
      "Next button not found, ending pagination\n",
      "Total unique reviews found: 100\n",
      "Scraped 100 total reviews\n",
      "Reviews saved to amazon_reviews_complete.csv\n",
      "Reviews saved to amazon_reviews_complete.json\n",
      "\n",
      "--- Review 1 ---\n",
      "Title: Amazons's Basics 3-Button USB wired mouse, works good, looks good, reduces the EMF\n",
      "Rating: rating\n",
      "Text: This Amazon Basics 3-Button USB wired mouse is easy to review. It was delivered in a solid, well protected box. installing it was easy. It fit well, functions well, is responsive, and the design remin...\n",
      "Reviewer: Coopra102\n",
      "Date: Reviewed in the United States on May 16, 2025\n",
      "\n",
      "--- Review 2 ---\n",
      "Title: Quick and easy\n",
      "Rating: rating\n",
      "Text: This is simply wonderful. All of a sudden one day, I was unable to scroll with my mouse. What a pain! I'd had that one for 2 years maybe. I'd say I got my money's worth. I ordered the same one and it ...\n",
      "Reviewer: zentrainer\n",
      "Date: Reviewed in the United States on May 28, 2025\n",
      "\n",
      "--- Review 3 ---\n",
      "Title: Perfect Old School Mouse\n",
      "Rating: rating\n",
      "Text: Honestly, I'm too old school to use a wireless mouse. I want something super simple that I can just plug in and go, and that's exactly what this is. Easy to use, long enough wire, and quality from Ama...\n",
      "Reviewer: Kevin R\n",
      "Date: Reviewed in the United States on June 3, 2025\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import json\n",
    "\n",
    "class AmazonReviewsScraper:\n",
    "    def __init__(self):\n",
    "        self.setup_driver()\n",
    "        \n",
    "    def setup_driver(self):\n",
    "        \"\"\"Setup Chrome driver with options\"\"\"\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "        chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "        chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "        chrome_options.add_argument(\"--start-maximized\")\n",
    "        \n",
    "        # You may need to specify the path to your chromedriver\n",
    "        # service = Service('/path/to/chromedriver')\n",
    "        # self.driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        \n",
    "        self.driver = webdriver.Chrome(options=chrome_options)\n",
    "        self.driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "        \n",
    "    def wait_for_element(self, selector, timeout=30, by=By.CSS_SELECTOR):\n",
    "        \"\"\"Wait for element with custom timeout and retry logic\"\"\"\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                element = WebDriverWait(self.driver, timeout).until(\n",
    "                    EC.presence_of_element_located((by, selector))\n",
    "                )\n",
    "                return element\n",
    "            except TimeoutException:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Timeout waiting for {selector}, retrying... (attempt {attempt + 1})\")\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    print(f\"Final timeout waiting for {selector}\")\n",
    "                    return None\n",
    "        return None\n",
    "    \n",
    "    def scrape_reviews(self, product_url, max_pages=None):\n",
    "        \"\"\"Scrape reviews from Amazon product page - if max_pages is None, scrape all pages\"\"\"\n",
    "        reviews_data = []\n",
    "        \n",
    "        try:\n",
    "            self.driver.get(product_url)\n",
    "            time.sleep(3)\n",
    "            \n",
    "            # First, try to scrape reviews from the product page\n",
    "            print(\"Attempting to scrape reviews from product page...\")\n",
    "            try:\n",
    "                # Wait for the customerReviews section with longer timeout\n",
    "                customer_reviews = self.wait_for_element(\"#customerReviews\", timeout=15, by=By.ID)\n",
    "                \n",
    "                if customer_reviews:\n",
    "                    # Try to find reviews on the main product page\n",
    "                    review_elements = self.driver.find_elements(By.CSS_SELECTOR, \"[data-hook='review']\")\n",
    "                    \n",
    "                    if review_elements:\n",
    "                        print(f\"Found {len(review_elements)} reviews on product page\")\n",
    "                        for review_element in review_elements:\n",
    "                            review_data = self.extract_review_data(review_element)\n",
    "                            if review_data:\n",
    "                                reviews_data.append(review_data)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping from product page: {str(e)}\")\n",
    "            \n",
    "            # Now try to navigate to the dedicated reviews page\n",
    "            print(\"Attempting to navigate to reviews page...\")\n",
    "            try:\n",
    "                # Try multiple selectors for \"See all reviews\" link\n",
    "                see_all_selectors = [\n",
    "                    \"[data-hook='see-all-reviews-link-foot']\",\n",
    "                    \"a[href*='product-reviews']\",\n",
    "                    \".cr-widget-FocalReviews a[href*='product-reviews']\",\n",
    "                    \".reviewsSection a[href*='product-reviews']\"\n",
    "                ]\n",
    "                \n",
    "                clicked = False\n",
    "                for selector in see_all_selectors:\n",
    "                    try:\n",
    "                        see_all_reviews = self.driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                        if see_all_reviews.is_displayed():\n",
    "                            # Scroll to element before clicking\n",
    "                            self.driver.execute_script(\"arguments[0].scrollIntoView(true);\", see_all_reviews)\n",
    "                            time.sleep(1)\n",
    "                            \n",
    "                            # Try JavaScript click first\n",
    "                            try:\n",
    "                                self.driver.execute_script(\"arguments[0].click();\", see_all_reviews)\n",
    "                                clicked = True\n",
    "                                print(\"Successfully clicked 'See all reviews' link\")\n",
    "                                break\n",
    "                            except:\n",
    "                                # If JS click fails, try regular click\n",
    "                                see_all_reviews.click()\n",
    "                                clicked = True\n",
    "                                print(\"Successfully clicked 'See all reviews' link\")\n",
    "                                break\n",
    "                    except (NoSuchElementException, Exception):\n",
    "                        continue\n",
    "                \n",
    "                if not clicked:\n",
    "                    print(\"Could not find or click 'See all reviews' link\")\n",
    "                    # If we can't click the link, try to construct the reviews URL directly\n",
    "                    if \"/dp/\" in product_url:\n",
    "                        asin = product_url.split(\"/dp/\")[1].split(\"/\")[0].split(\"?\")[0]\n",
    "                        reviews_url = f\"https://www.amazon.com/product-reviews/{asin}/\"\n",
    "                        print(f\"Trying direct reviews URL: {reviews_url}\")\n",
    "                        self.driver.get(reviews_url)\n",
    "                        clicked = True\n",
    "                \n",
    "                if clicked:\n",
    "                    time.sleep(3)\n",
    "                    \n",
    "                    # Scrape reviews from multiple pages\n",
    "                    page = 0\n",
    "                    consecutive_failures = 0\n",
    "                    max_consecutive_failures = 3\n",
    "                    \n",
    "                    while True:\n",
    "                        page += 1\n",
    "                        \n",
    "                        # If max_pages is set and we've reached it, break\n",
    "                        if max_pages is not None and page > max_pages:\n",
    "                            print(f\"Reached maximum pages limit ({max_pages})\")\n",
    "                            break\n",
    "                            \n",
    "                        print(f\"Scraping reviews page {page}...\")\n",
    "                        \n",
    "                        try:\n",
    "                            # Wait for reviews to load with retry logic\n",
    "                            reviews_found = False\n",
    "                            for attempt in range(3):  # Try 3 times to find reviews\n",
    "                                try:\n",
    "                                    WebDriverWait(self.driver, 20).until(\n",
    "                                        EC.presence_of_element_located((By.CSS_SELECTOR, \"[data-hook='review']\"))\n",
    "                                    )\n",
    "                                    reviews_found = True\n",
    "                                    break\n",
    "                                except TimeoutException:\n",
    "                                    if attempt < 2:\n",
    "                                        print(f\"Timeout finding reviews on page {page}, retrying...\")\n",
    "                                        time.sleep(3)\n",
    "                                        self.driver.refresh()\n",
    "                                        time.sleep(3)\n",
    "                                    else:\n",
    "                                        print(f\"Final timeout finding reviews on page {page}\")\n",
    "                            \n",
    "                            if not reviews_found:\n",
    "                                consecutive_failures += 1\n",
    "                                if consecutive_failures >= max_consecutive_failures:\n",
    "                                    print(f\"Failed to find reviews on {consecutive_failures} consecutive pages. Stopping.\")\n",
    "                                    break\n",
    "                                continue\n",
    "                            \n",
    "                            # Reset consecutive failures counter\n",
    "                            consecutive_failures = 0\n",
    "                            \n",
    "                            # Get all review elements on current page\n",
    "                            review_elements = self.driver.find_elements(By.CSS_SELECTOR, \"[data-hook='review']\")\n",
    "                            print(f\"Found {len(review_elements)} reviews on page {page}\")\n",
    "                            \n",
    "                            if len(review_elements) == 0:\n",
    "                                print(\"No reviews found on this page, ending scraping\")\n",
    "                                break\n",
    "                            \n",
    "                            # Extract review data\n",
    "                            page_reviews_count = 0\n",
    "                            for review_element in review_elements:\n",
    "                                review_data = self.extract_review_data(review_element)\n",
    "                                if review_data:\n",
    "                                    reviews_data.append(review_data)\n",
    "                                    page_reviews_count += 1\n",
    "                            \n",
    "                            print(f\"Successfully extracted {page_reviews_count} reviews from page {page}\")\n",
    "                            \n",
    "                            # Try to go to next page\n",
    "                            try:\n",
    "                                next_button = self.driver.find_element(By.CSS_SELECTOR, \"li.a-last a\")\n",
    "                                if next_button and \"a-disabled\" not in next_button.get_attribute(\"class\"):\n",
    "                                    self.driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "                                    time.sleep(2)\n",
    "                                    \n",
    "                                    # Try clicking next button with retry\n",
    "                                    clicked_next = False\n",
    "                                    for attempt in range(3):\n",
    "                                        try:\n",
    "                                            self.driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                                            clicked_next = True\n",
    "                                            break\n",
    "                                        except Exception as e:\n",
    "                                            if attempt < 2:\n",
    "                                                print(f\"Failed to click next button, retrying... (attempt {attempt + 1})\")\n",
    "                                                time.sleep(2)\n",
    "                                            else:\n",
    "                                                print(f\"Failed to click next button after 3 attempts: {str(e)}\")\n",
    "                                    \n",
    "                                    if not clicked_next:\n",
    "                                        print(\"Could not proceed to next page\")\n",
    "                                        break\n",
    "                                    \n",
    "                                    time.sleep(5)  # Wait longer for page to load\n",
    "                                else:\n",
    "                                    print(\"No more pages available (next button disabled)\")\n",
    "                                    break\n",
    "                            except NoSuchElementException:\n",
    "                                print(\"Next button not found, ending pagination\")\n",
    "                                break\n",
    "                                \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error on page {page}: {str(e)}\")\n",
    "                            consecutive_failures += 1\n",
    "                            if consecutive_failures >= max_consecutive_failures:\n",
    "                                print(f\"Too many consecutive failures ({consecutive_failures}). Stopping.\")\n",
    "                                break\n",
    "                            time.sleep(3)\n",
    "                            continue\n",
    "                            \n",
    "            except Exception as e:\n",
    "                print(f\"Error navigating to reviews page: {str(e)}\")\n",
    "                # If all else fails, try to scrape from current page\n",
    "                try:\n",
    "                    review_elements = self.driver.find_elements(By.CSS_SELECTOR, \"[data-hook='review']\")\n",
    "                    if review_elements:\n",
    "                        print(f\"Scraping {len(review_elements)} reviews from current page\")\n",
    "                        for review_element in review_elements:\n",
    "                            review_data = self.extract_review_data(review_element)\n",
    "                            if review_data:\n",
    "                                reviews_data.append(review_data)\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {str(e)}\")\n",
    "            \n",
    "        # Remove duplicates based on review text\n",
    "        seen_reviews = set()\n",
    "        unique_reviews = []\n",
    "        for review in reviews_data:\n",
    "            review_key = review.get('text', '')[:100]  # Use first 100 chars as key\n",
    "            if review_key not in seen_reviews:\n",
    "                seen_reviews.add(review_key)\n",
    "                unique_reviews.append(review)\n",
    "        \n",
    "        print(f\"Total unique reviews found: {len(unique_reviews)}\")\n",
    "        return unique_reviews\n",
    "    \n",
    "    def extract_review_data(self, review_element):\n",
    "        \"\"\"Extract data from a single review element\"\"\"\n",
    "        try:\n",
    "            review_data = {}\n",
    "            \n",
    "            # Review title\n",
    "            try:\n",
    "                title_element = review_element.find_element(By.CSS_SELECTOR, \"[data-hook='review-title']\")\n",
    "                review_data['title'] = title_element.text.strip()\n",
    "            except NoSuchElementException:\n",
    "                review_data['title'] = \"No title\"\n",
    "            \n",
    "            # Star rating\n",
    "            try:\n",
    "                rating_element = review_element.find_element(By.CSS_SELECTOR, \"[data-hook='review-star-rating']\")\n",
    "                rating_text = rating_element.get_attribute(\"class\")\n",
    "                # Extract rating from class name (e.g., \"a-star-5\" -> \"5\")\n",
    "                rating = rating_text.split()[-1].split('-')[-1] if 'star' in rating_text else \"No rating\"\n",
    "                review_data['rating'] = rating\n",
    "            except NoSuchElementException:\n",
    "                review_data['rating'] = \"No rating\"\n",
    "            \n",
    "            # Review text\n",
    "            try:\n",
    "                text_element = review_element.find_element(By.CSS_SELECTOR, \"[data-hook='review-body']\")\n",
    "                review_data['text'] = text_element.text.strip()\n",
    "            except NoSuchElementException:\n",
    "                review_data['text'] = \"No review text\"\n",
    "            \n",
    "            # Reviewer name\n",
    "            try:\n",
    "                name_element = review_element.find_element(By.CSS_SELECTOR, \"[data-hook='genome-widget'] .a-profile-name\")\n",
    "                review_data['reviewer_name'] = name_element.text.strip()\n",
    "            except NoSuchElementException:\n",
    "                review_data['reviewer_name'] = \"Anonymous\"\n",
    "            \n",
    "            # Review date\n",
    "            try:\n",
    "                date_element = review_element.find_element(By.CSS_SELECTOR, \"[data-hook='review-date']\")\n",
    "                review_data['date'] = date_element.text.strip()\n",
    "            except NoSuchElementException:\n",
    "                review_data['date'] = \"No date\"\n",
    "            \n",
    "            # Verified purchase\n",
    "            try:\n",
    "                verified_element = review_element.find_element(By.CSS_SELECTOR, \"[data-hook='avp-badge']\")\n",
    "                review_data['verified_purchase'] = \"Yes\" if verified_element else \"No\"\n",
    "            except NoSuchElementException:\n",
    "                review_data['verified_purchase'] = \"No\"\n",
    "            \n",
    "            # Helpful votes\n",
    "            try:\n",
    "                helpful_element = review_element.find_element(By.CSS_SELECTOR, \"[data-hook='helpful-vote-statement']\")\n",
    "                review_data['helpful_votes'] = helpful_element.text.strip()\n",
    "            except NoSuchElementException:\n",
    "                review_data['helpful_votes'] = \"0\"\n",
    "            \n",
    "            return review_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting review data: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def save_to_csv(self, reviews_data, filename=\"amazon_reviews.csv\"):\n",
    "        \"\"\"Save reviews data to CSV file\"\"\"\n",
    "        if not reviews_data:\n",
    "            print(\"No reviews data to save\")\n",
    "            return\n",
    "            \n",
    "        fieldnames = ['title', 'rating', 'text', 'reviewer_name', 'date', 'verified_purchase', 'helpful_votes']\n",
    "        \n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(reviews_data)\n",
    "        \n",
    "        print(f\"Reviews saved to {filename}\")\n",
    "    \n",
    "    def save_to_json(self, reviews_data, filename=\"amazon_reviews.json\"):\n",
    "        \"\"\"Save reviews data to JSON file\"\"\"\n",
    "        if not reviews_data:\n",
    "            print(\"No reviews data to save\")\n",
    "            return\n",
    "            \n",
    "        with open(filename, 'w', encoding='utf-8') as jsonfile:\n",
    "            json.dump(reviews_data, jsonfile, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"Reviews saved to {filename}\")\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close the browser\"\"\"\n",
    "        self.driver.quit()\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize scraper\n",
    "    scraper = AmazonReviewsScraper()\n",
    "    \n",
    "    # Amazon product URL\n",
    "    product_url = \"https://www.amazon.com/Amazon-Basics-3-Button-Scrolling-Tracking/dp/B005EJH6RW\"\n",
    "    \n",
    "    try:\n",
    "        # Scrape ALL reviews (no page limit)\n",
    "        print(\"Starting to scrape ALL reviews...\")\n",
    "        reviews = scraper.scrape_reviews(product_url, max_pages=None)  # Set to None for unlimited\n",
    "        \n",
    "        print(f\"Scraped {len(reviews)} total reviews\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        scraper.save_to_csv(reviews, \"amazon_reviews_complete.csv\")\n",
    "        \n",
    "        # Save to JSON\n",
    "        scraper.save_to_json(reviews, \"amazon_reviews_complete.json\")\n",
    "        \n",
    "        # Print first few reviews as example\n",
    "        for i, review in enumerate(reviews[:3]):\n",
    "            print(f\"\\n--- Review {i+1} ---\")\n",
    "            print(f\"Title: {review['title']}\")\n",
    "            print(f\"Rating: {review['rating']}\")\n",
    "            print(f\"Text: {review['text'][:200]}...\")\n",
    "            print(f\"Reviewer: {review['reviewer_name']}\")\n",
    "            print(f\"Date: {review['date']}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "    finally:\n",
    "        # Close browser\n",
    "        scraper.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
